########
# Copyright (c) 2017 MSO4SC
# Author(s) javier.carnero@atos.net
#           guillaume.dolle@cemosis.fr
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tosca_definitions_version: cloudify_dsl_1_3

# data_types:

#   hifimagnet.test:
#     description: Hifimagnet test details
#     properties:
#       exec:
#         description: executable
#         type: string
#       cfgfile:
#         description: Feelpp cfg file
#         type: string
#       result:
#         description: expected test result
#         type: string

imports:
    # to speed things up, it is possible to download this file,
    - https://raw.githubusercontent.com/cloudify-cosmo/cloudify-manager/18.1.11/resources/rest-service/cloudify/types/types.yaml
    # - https://raw.githubusercontent.com/MSO4SC/cloudify-hpc-plugin/master/plugin.yaml
    - https://raw.githubusercontent.com/Trophime/cloudify-hpc-plugin/master/plugin.yaml

inputs:
    # Monitor
    monitor_entrypoint:
        description: Monitor entrypoint IP
        default: "193.144.35.146"
        type: string

    # Job prefix name
    job_prefix:
        description: Job name prefix in HPCs
        default: "mso4sc"
        type: string

    # CESGA FTII parameters
    mso4sc_hpc_primary:
        description: FTII connection credentials
        default: {}

    parallel_tasks:
        description: number of tasks/processes to run in parallel
        default: 2

    max_time:
        description: maximum allowed time for run (minutes and seconds)
        default: '00:30:00'

   #  hpc_partition:
   #      description: maximum allowed time for run (minutes and seconds)

   #  hpc_reservation:
   #      description: maximum allowed time for run (minutes and seconds)

   # hpc_modules:
   #      description: maximum allowed time for run (minutes and seconds)
    
    mso4sc_dataset_input_url:
        description: url to retrieve for case file
        default: ""

    containerdir:
        description: Container directory
        default: "${LUSTRE}/singularity_images"

    execfile:
        description: executable file
        default: "feelpp_hfm_thermoelectric_model_3D_V1T1_N1"

    cfgfile:
        description: configuration file
        default: "/usr/local/share/hifimagnet/ThermoElectricModel/thermoelectric_3D_V1T1_N1_cvg.cfg"

    singularity_image_uri:
        description: URI pointing to the singularity image
        default: "shub://sregistry.srv.cesga.es/mso4sc/hifimagnet:tag"

    singularity_image_filename:
        description: Filename of the singularity image
        default: "feelpp_hifimagnet-mso4sc.simg"

node_templates:
    primary_hpc:
        type: hpc.nodes.Compute
        properties:
            config: { get_input: mso4sc_hpc_primary }
            external_monitor_entrypoint: { get_input: monitor_entrypoint }
            # monitor_orchestrator_available: True
            job_prefix: { get_input: job_prefix }
            base_dir: "$HOME"
            workdir_prefix: "fuck"
            # simulate: True  # COMMENT to test against a real HPC

    job_test:
        type: hpc.nodes.singularity_job
        properties:
            job_options:
                # modules:
                #     - gcc/6.1.0
                #     - openmpi/1.10.2
                #     - singularity/2.4.2
                partition: "euler"
                # partition: { get_attribute: [primary_hpc, hpc_partition] }
                # reservation: 'MSO4SC'
                home: '${HOME}:/home/${USER}'
                # volumes:
                #     - '/scratch'
                #     - '${LUSTRE}/feel:/feel'
                volumes:
                    - '${HOME}/feel:/feel'
                command: { concat: [ { get_input: execfile }, ' --config-file ', { get_input: cfgfile } ] }
                tasks: { get_input: parallel_tasks }
                max_time: { get_input: max_time }
                image: { concat: [ { get_input: containerdir }, '/', { get_input: singularity_image_filename } ] }
                skip_cleanup: true
            skip_cleanup: true
            deployment:
                bootstrap: 'scripts/bootstrap.sh'
                revert: 'scripts/revert.sh'
                inputs:
                    - { get_input: containerdir }
                    - { get_input: singularity_image_filename }

        relationships:
            - type: job_contained_in_hpc
              target: primary_hpc

outputs:
    job_test:
        description: feelpp_hfm_test results
        value: { get_attribute: [job_test, job_name] }
